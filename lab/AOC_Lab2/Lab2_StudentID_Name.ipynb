{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "sHXk_L8g3fDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVH9mlCdXrkw"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "import random\n",
        "from collections import OrderedDict, defaultdict\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "\n",
        "\n",
        "no_cuda = False\n",
        "use_gpu = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#Dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "#Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk1U6PcMXtDB",
        "outputId": "58b165e2-e66b-41c5-987d-4fcc1b6a26fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16215578.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 312432.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5245944.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 14973839.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create NN model"
      ],
      "metadata": {
        "id": "JzMtMm9n3hsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.backbone = nn.Sequential(\n",
        "      nn.Linear(28*28, 120, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(120, 84, bias=False),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(84, 10, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 * 28) #transform 28*28 figure to 784 vector\n",
        "    x = self.backbone(x)\n",
        "    return x\n",
        "\n",
        "FP32_model = ToyModel()\n",
        "print(FP32_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-pKE7xJbOc7",
        "outputId": "fce122fd-5aa8-4d0c-fe2c-94bb60cc64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToyModel(\n",
            "  (backbone): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=120, bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=120, out_features=84, bias=False)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=84, out_features=10, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  #Set the model to train mode\n",
        "  model.train()\n",
        "  for batch, (x, y) in enumerate(dataloader):\n",
        "    if use_gpu:\n",
        "      x, y = x.cuda(), y.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    #forward\n",
        "    pred = model(x)\n",
        "\n",
        "    #loss\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #backward\n",
        "    loss.backward()\n",
        "\n",
        "    #optimize\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(x)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  #set model to evaluate mode\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      if use_gpu:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "      pred = model(x)\n",
        "      test_loss = loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item() #calculate accuracy\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "MOyeqSPDbvr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 3\n",
        "loss_fn = nn.CrossEntropyLoss() #define loss function\n",
        "optimizer = torch.optim.SGD(FP32_model.parameters(), lr=learning_rate, momentum=0.9)  #define optimizer\n",
        "\n",
        "FP32_model.to(device) #let model on GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LsfzIw4b1AU",
        "outputId": "03aeb700-d0fe-4e88-a24e-d000b63c4184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToyModel(\n",
              "  (backbone): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=120, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "for i in range(epochs):\n",
        "  print(f\"Epoch {i+1}\\n-------------------------------\")\n",
        "  train_loop(train_loader, FP32_model, loss_fn, optimizer)\n",
        "  test_loop(test_loader, FP32_model, loss_fn)"
      ],
      "metadata": {
        "id": "LH6kt0eqb9tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization definition"
      ],
      "metadata": {
        "id": "oTAK3-fH3qGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Question 1.####\n",
        "\n",
        "Use\n",
        ">$S=(r_{\\mathrm{max}} - r_{\\mathrm{min}}) / (q_{\\mathrm{max}} - q_{\\mathrm{min}})$\n",
        "\n",
        ">$Z = q_{\\mathrm{min}} - r_{\\mathrm{min}} / S$\n",
        "\n",
        "to calculate scale factor and zero point of a tensor\n"
      ],
      "metadata": {
        "id": "0lWzxrde4G5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scale_and_zero_point(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -2**(bitwidth-1), 2**(bitwidth-1) - 1\n",
        "  fp_min = fp32_tensor.min().item()\n",
        "  fp_max = fp32_tensor.max().item()\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  scale = ( __ - __ ) / ( __ - __ )\n",
        "  zero_point = __ - __ / __\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "\n",
        "  zero_point = round(zero_point)          #round\n",
        "  zero_point = max(q_min, min(zero_point, q_max)) #clip\n",
        "\n",
        "  return scale, int(zero_point)"
      ],
      "metadata": {
        "id": "kJIr-5SpcgQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Question 2.####\n",
        "\n",
        "Use $q=r/S + Z$ to quantize a tensor"
      ],
      "metadata": {
        "id": "D4YA7ano5nS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_quantize(fp32_tensor, bitwidth=8):\n",
        "  q_min, q_max = -2**(bitwidth-1), 2**(bitwidth-1) - 1\n",
        "\n",
        "  scale, zero_point = get_scale_and_zero_point(fp32_tensor)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  q_tensor = torch.round( __ / __ ) + __\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp\n",
        "  q_tensor = torch.clamp(q_tensor, q_min, q_max)\n",
        "  return q_tensor, scale, zero_point"
      ],
      "metadata": {
        "id": "sBMKB5Le54wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Question 3.####\n",
        "\n",
        "Use\n",
        "> $q_{\\mathrm{output}} = M * \\mathrm{Linear}[q_{\\mathrm{input}}, q_{\\mathrm{weight}}] + Z_{\\mathrm{output}}$\n",
        "\n",
        "> $M = S_{\\mathrm{input}} * S_{\\mathrm{weight}} / S_{\\mathrm{output}}$\n",
        "\n",
        "to compute quantized linear operation"
      ],
      "metadata": {
        "id": "0taJXSmz6KDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantized_linear(input, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, device, bitwidth=8, activation_bitwidth=8):\n",
        "  input, weights = input.to(device), weights.to(device)\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  M = __ * __ / __\n",
        "  output = torch.nn.functional.linear((input - __ ), (weights - __ ))\n",
        "  output *= M\n",
        "  output += output_zero_point\n",
        "\n",
        "  #####################################################\n",
        "\n",
        "  #clamp and round\n",
        "  output = output.round().clamp(-2**(activation_bitwidth-1), 2**(activation_bitwidth-1)-1)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "sbXY0vaCcn7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design quantized linear layer and preprocess"
      ],
      "metadata": {
        "id": "vK10k10R7II7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedLinear(nn.Module):\n",
        "  def __init__(self, weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point, bitwidth=8, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.weights = weights\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.weight_scale, self.weight_zero_point = weight_scale, weight_zero_point\n",
        "    self.output_scale, self.output_zero_point = output_scale, output_zero_point\n",
        "\n",
        "    self.bitwidth = bitwidth\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "\n",
        "  def forward(self, x):\n",
        "    return quantized_linear(x, self.weights, self.input_scale, self.weight_scale, self.output_scale, self.input_zero_point, self.weight_zero_point, self.output_zero_point, device)\n",
        "  def __repr__(self):\n",
        "    return f\"QuantizedLinear(in_channels={self.weights.size(1)}, out_channels={self.weights.size(0)})\"\n",
        "\n",
        "#Transform input data to correct integer range\n",
        "class Preprocess(nn.Module):\n",
        "  def __init__(self, input_scale, input_zero_point, activation_bitwidth=8):\n",
        "    super().__init__()\n",
        "    self.input_scale, self.input_zero_point = input_scale, input_zero_point\n",
        "    self.activation_bitwidth = activation_bitwidth\n",
        "  def forward(self, x):\n",
        "    x = x / self.input_scale + self.input_zero_point\n",
        "    return x"
      ],
      "metadata": {
        "id": "IwrXNVKadKfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calibration"
      ],
      "metadata": {
        "id": "EUpiPDiu7RCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add hook to record the min max value of the activation\n",
        "input_activation = {}\n",
        "output_activation = {}\n",
        "\n",
        "#Define a hook to record the feature map of each layer\n",
        "def add_range_recoder_hook(model):\n",
        "    import functools\n",
        "    def _record_range(self, x, y, module_name):\n",
        "        x = x[0]\n",
        "        input_activation[module_name] = x.detach()\n",
        "        output_activation[module_name] = y.detach()\n",
        "\n",
        "    all_hooks = []\n",
        "    for name, m in model.named_modules():\n",
        "        if isinstance(m, (nn.Linear, nn.ReLU)):\n",
        "            all_hooks.append(m.register_forward_hook(\n",
        "                functools.partial(_record_range, module_name=name)))\n",
        "    return all_hooks\n",
        "\n",
        "hooks = add_range_recoder_hook(FP32_model)\n",
        "sample_data = iter(train_loader).__next__()[0].to(device) #Use a batch of training data to calibrate\n",
        "FP32_model(sample_data) #Forward to use hook\n",
        "\n",
        "# remove hooks\n",
        "for h in hooks:\n",
        "    h.remove()\n"
      ],
      "metadata": {
        "id": "cBdXFnr5dZqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantize model"
      ],
      "metadata": {
        "id": "YVf8vpiVTsDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#copy original model\n",
        "quantized_model = copy.deepcopy(FP32_model)\n",
        "\n",
        "#Record each layer in original model\n",
        "quantized_backbone = []\n",
        "i = 0\n",
        "\n",
        "#Record input scale and zero point\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[\"backbone.0\"])\n",
        "preprocess = Preprocess(input_scale, input_zero_point)\n",
        "quantized_backbone.append(preprocess)\n",
        "\n",
        "#Record Linear + ReLU of the model (except the last Linear)\n",
        "while i < len(quantized_model.backbone) - 1:\n",
        "  if isinstance(quantized_model.backbone[i], nn.Linear) and isinstance(quantized_model.backbone[i+1], nn.ReLU):\n",
        "    linear = quantized_model.backbone[i]\n",
        "    linear_name = f\"backbone.{i}\"\n",
        "    relu = quantized_model.backbone[i + 1]\n",
        "    relu_name = f\"backbone.{i + 1}\"\n",
        "\n",
        "    #Use the calibration data to calculate scale and zero point of each layer\n",
        "    input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "    output_scale, output_zero_point = get_scale_and_zero_point(output_activation[relu_name])\n",
        "    quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "\n",
        "    quantizedLinear = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "\n",
        "    quantized_backbone.append(quantizedLinear)\n",
        "    i += 2\n",
        "\n",
        "#Record the last Linear layer\n",
        "linear = quantized_model.backbone[4]\n",
        "linear_name = f\"backbone.4\"\n",
        "input_scale, input_zero_point = get_scale_and_zero_point(input_activation[linear_name])\n",
        "output_scale, output_zero_point = get_scale_and_zero_point(output_activation[linear_name])\n",
        "quantized_weights, weight_scale, weight_zero_point = linear_quantize(linear.weight.data)\n",
        "quantizedLinear = QuantizedLinear(quantized_weights, input_scale, weight_scale, output_scale, input_zero_point, weight_zero_point, output_zero_point)\n",
        "quantized_backbone.append(quantizedLinear)\n",
        "\n",
        "\n",
        "quantized_model.backbone = nn.Sequential(*quantized_backbone)"
      ],
      "metadata": {
        "id": "SVh-SRj8eOrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRB96PKbfNX4",
        "outputId": "58ce882a-3521-4b40-ff98-44dcea373546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToyModel(\n",
            "  (backbone): Sequential(\n",
            "    (0): Preprocess()\n",
            "    (1): QuantizedLinear(in_channels=784, out_channels=120)\n",
            "    (2): QuantizedLinear(in_channels=120, out_channels=84)\n",
            "    (3): QuantizedLinear(in_channels=84, out_channels=10)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "BMccqTL6URaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(test_loader, FP32_model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRMXzNeCgDuq",
        "outputId": "0fa65b9f-3a60-41e0-a935-a601a8db0484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.000875 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(test_loader, quantized_model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knTzO1mbheBe",
        "outputId": "411fc256-b7ea-4757-9f75-6acaae605324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.004596 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}